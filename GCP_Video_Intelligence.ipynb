{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-videointelligence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "GkJoHx-FbklB",
        "outputId": "23aa2a35-e136-41a7-dcb0-70bbde228057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-cloud-videointelligence\n",
            "  Downloading google_cloud_videointelligence-2.15.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.19.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-videointelligence) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-videointelligence) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-videointelligence) (4.25.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.69.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-videointelligence) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence) (2024.12.14)\n",
            "Downloading google_cloud_videointelligence-2.15.0-py2.py3-none-any.whl (269 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/269.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m266.2/269.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.8/269.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-cloud-videointelligence\n",
            "Successfully installed google-cloud-videointelligence-2.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "5657cb3e2a8e410a8f3787f80eb496fa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z2Q5DiIjbYy2"
      },
      "outputs": [],
      "source": [
        "from datetime import timedelta\n",
        "from typing import Optional, Sequence, cast\n",
        "\n",
        "from google.cloud import videointelligence_v1 as vi\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/content/perfect-eon-449007-i8-8d3c769375fd.json'"
      ],
      "metadata": {
        "id": "XTbL279qga2Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_labels( video_uri: str,mode: vi.LabelDetectionMode,segments: Optional[Sequence[vi.VideoSegment]] = None,) -> vi.VideoAnnotationResults:\n",
        "    video_client = vi.VideoIntelligenceServiceClient()\n",
        "    features = [vi.Feature.LABEL_DETECTION]\n",
        "    config = vi.LabelDetectionConfig(label_detection_mode=mode)\n",
        "    context = vi.VideoContext(segments=segments, label_detection_config=config)\n",
        "    request = vi.AnnotateVideoRequest(\n",
        "        input_uri=video_uri,\n",
        "        features=features,\n",
        "        video_context=context,\n",
        "    )\n",
        "\n",
        "    print(f'Processing video \"{video_uri}\"...')\n",
        "    operation = video_client.annotate_video(request)\n",
        "\n",
        "    # Wait for operation to complete\n",
        "    response = cast(vi.AnnotateVideoResponse, operation.result())\n",
        "    # A single video is processed\n",
        "    results = response.annotation_results[0]\n",
        "\n",
        "    return results\n",
        "\n",
        "video_uri = \"gs://cloud-samples-data/video/JaneGoodall.mp4\"\n",
        "mode = vi.LabelDetectionMode.SHOT_MODE\n",
        "segment = vi.VideoSegment(\n",
        "    start_time_offset=timedelta(seconds=0),\n",
        "    end_time_offset=timedelta(seconds=37),\n",
        ")\n",
        "\n",
        "results = detect_labels(video_uri, mode, [segment])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu6eJM8JgkWG",
        "outputId": "cbe1cff8-ab7a-43ce-da6a-fc9832c2f8e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video \"gs://cloud-samples-data/video/JaneGoodall.mp4\"...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_video_labels(results: vi.VideoAnnotationResults):\n",
        "    labels = sorted_by_first_segment_confidence(results.segment_label_annotations)\n",
        "\n",
        "    print(f\" Video labels: {len(labels)} \".center(80, \"-\"))\n",
        "    for label in labels:\n",
        "        categories = category_entities_to_str(label.category_entities)\n",
        "        for segment in label.segments:\n",
        "            confidence = segment.confidence\n",
        "            t1 = segment.segment.start_time_offset.total_seconds()\n",
        "            t2 = segment.segment.end_time_offset.total_seconds()\n",
        "            print(\n",
        "                f\"{confidence:4.0%}\",\n",
        "                f\"{t1:7.3f}\",\n",
        "                f\"{t2:7.3f}\",\n",
        "                f\"{label.entity.description}{categories}\",\n",
        "                sep=\" | \",\n",
        "            )"
      ],
      "metadata": {
        "id": "M1udyvpcgqfM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sorted_by_first_segment_confidence(\n",
        "    labels: Sequence[vi.LabelAnnotation],\n",
        ") -> Sequence[vi.LabelAnnotation]:\n",
        "    def first_segment_confidence(label: vi.LabelAnnotation) -> float:\n",
        "        return label.segments[0].confidence\n",
        "\n",
        "    return sorted(labels, key=first_segment_confidence, reverse=True)"
      ],
      "metadata": {
        "id": "uoQFrKjng18K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def category_entities_to_str(category_entities: Sequence[vi.Entity]) -> str:\n",
        "    if not category_entities:\n",
        "        return \"\"\n",
        "    entities = \", \".join([e.description for e in category_entities])\n",
        "    return f\" ({entities})\""
      ],
      "metadata": {
        "id": "78e2nz9VhP7p"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_video_labels(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BleiLq7nin2Y",
        "outputId": "3862e465-152f-41e3-9d84-713973192e35"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------- Video labels: 10 -------------------------------\n",
            " 96% |   0.000 |  36.960 | nature\n",
            " 74% |   0.000 |  36.960 | vegetation\n",
            " 59% |   0.000 |  36.960 | tree (plant)\n",
            " 56% |   0.000 |  36.960 | forest (geographical feature)\n",
            " 49% |   0.000 |  36.960 | leaf (plant)\n",
            " 43% |   0.000 |  36.960 | flora (plant)\n",
            " 38% |   0.000 |  36.960 | nature reserve (geographical feature)\n",
            " 37% |   0.000 |  36.960 | woodland (forest)\n",
            " 35% |   0.000 |  36.960 | water resources (water)\n",
            " 32% |   0.000 |  36.960 | sunlight (light)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_shot_labels(results: vi.VideoAnnotationResults):\n",
        "    labels = sorted_by_first_segment_start_and_confidence(\n",
        "        results.shot_label_annotations\n",
        "    )\n",
        "\n",
        "    print(f\" Shot labels: {len(labels)} \".center(80, \"-\"))\n",
        "    video_labels = []\n",
        "    for label in labels:\n",
        "        categories = category_entities_to_str(label.category_entities)\n",
        "        label_description = label.entity.description\n",
        "        print(f\"{label.entity.description}{categories}\")\n",
        "        for segment in label.segments:\n",
        "            confidence = segment.confidence\n",
        "            t1 = segment.segment.start_time_offset.total_seconds()\n",
        "            t2 = segment.segment.end_time_offset.total_seconds()\n",
        "            print(f\"{confidence:4.0%} | {t1:7.3f} | {t2:7.3f}\")\n",
        "        if label_description not in video_labels:\n",
        "            video_labels.append(label_description)\n",
        "    return video_labels"
      ],
      "metadata": {
        "id": "LJ6cqoSxipr2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sorted_by_first_segment_start_and_confidence(\n",
        "    labels: Sequence[vi.LabelAnnotation],\n",
        ") -> Sequence[vi.LabelAnnotation]:\n",
        "    def first_segment_start_and_confidence(label: vi.LabelAnnotation):\n",
        "        first_segment = label.segments[0]\n",
        "        ms = first_segment.segment.start_time_offset.total_seconds()\n",
        "        return (ms, -first_segment.confidence)\n",
        "\n",
        "    return sorted(labels, key=first_segment_start_and_confidence)"
      ],
      "metadata": {
        "id": "kdVAAotZizE7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_labels = get_shot_labels(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRT3aNREi1C2",
        "outputId": "c218ed77-fa3d-4d98-f60a-046e3106c17e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------- Shot labels: 29 --------------------------------\n",
            "planet (astronomical object)\n",
            " 83% |   0.000 |  12.880\n",
            "earth (planet)\n",
            " 53% |   0.000 |  12.880\n",
            "water resources (water)\n",
            " 43% |   0.000 |  12.880\n",
            "aerial photography (photography)\n",
            " 43% |   0.000 |  12.880\n",
            "vegetation\n",
            " 32% |   0.000 |  12.880\n",
            " 92% |  12.920 |  21.680\n",
            " 83% |  21.720 |  27.880\n",
            " 77% |  27.920 |  31.800\n",
            " 76% |  31.840 |  34.720\n",
            "nature\n",
            " 96% |  12.920 |  21.680\n",
            " 96% |  21.720 |  27.880\n",
            " 96% |  27.920 |  31.800\n",
            " 96% |  31.840 |  34.720\n",
            " 49% |  34.760 |  36.960\n",
            "leaf (plant)\n",
            " 75% |  12.920 |  21.680\n",
            " 37% |  21.720 |  27.880\n",
            "sunlight (light)\n",
            " 60% |  12.920 |  21.680\n",
            " 46% |  27.920 |  31.800\n",
            "flora (plant)\n",
            " 57% |  12.920 |  21.680\n",
            "moisture (water)\n",
            " 38% |  12.920 |  21.680\n",
            "tree (plant)\n",
            " 98% |  27.920 |  31.800\n",
            "forest (geographical feature)\n",
            " 90% |  27.920 |  31.800\n",
            " 37% |  31.840 |  34.720\n",
            "grove (tree)\n",
            " 77% |  27.920 |  31.800\n",
            "woodland (forest)\n",
            " 76% |  27.920 |  31.800\n",
            "ecosystem (geographical feature)\n",
            " 58% |  27.920 |  31.800\n",
            "old growth forest (forest)\n",
            " 41% |  27.920 |  31.800\n",
            "temperate broadleaf and mixed forest (geographical feature)\n",
            " 38% |  27.920 |  31.800\n",
            "nature reserve (geographical feature)\n",
            " 37% |  27.920 |  31.800\n",
            "jungle (geographical feature)\n",
            " 36% |  27.920 |  31.800\n",
            " 44% |  31.840 |  34.720\n",
            "stream (geographical feature)\n",
            " 57% |  31.840 |  34.720\n",
            "moss (plant)\n",
            " 42% |  31.840 |  34.720\n",
            "rainforest (forest)\n",
            " 36% |  31.840 |  34.720\n",
            "insect (animal)\n",
            " 93% |  34.760 |  36.960\n",
            "moths and butterflies (insect)\n",
            " 85% |  34.760 |  36.960\n",
            "butterfly (insect, animal)\n",
            " 84% |  34.760 |  36.960\n",
            "monarch butterfly (butterfly)\n",
            " 48% |  34.760 |  36.960\n",
            "animal\n",
            " 44% |  34.760 |  36.960\n",
            "invertebrate (animal)\n",
            " 42% |  34.760 |  36.960\n",
            "pollinator (animal)\n",
            " 37% |  34.760 |  36.960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_labels"
      ],
      "metadata": {
        "id": "b1VBSE8Vi5FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e706bf0d-2ea7-4041-99e4-9dbc41e2f4a5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['planet',\n",
              " 'earth',\n",
              " 'water resources',\n",
              " 'aerial photography',\n",
              " 'vegetation',\n",
              " 'nature',\n",
              " 'leaf',\n",
              " 'sunlight',\n",
              " 'flora',\n",
              " 'moisture',\n",
              " 'tree',\n",
              " 'forest',\n",
              " 'grove',\n",
              " 'woodland',\n",
              " 'ecosystem',\n",
              " 'old growth forest',\n",
              " 'temperate broadleaf and mixed forest',\n",
              " 'nature reserve',\n",
              " 'jungle',\n",
              " 'stream',\n",
              " 'moss',\n",
              " 'rainforest',\n",
              " 'insect',\n",
              " 'moths and butterflies',\n",
              " 'butterfly',\n",
              " 'monarch butterfly',\n",
              " 'animal',\n",
              " 'invertebrate',\n",
              " 'pollinator']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCP Video Transcribe"
      ],
      "metadata": {
        "id": "uyTJFVb_jlwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import videointelligence"
      ],
      "metadata": {
        "id": "DcJBJjKAj8mT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_client = videointelligence.VideoIntelligenceServiceClient()\n",
        "features = [videointelligence.Feature.SPEECH_TRANSCRIPTION]\n",
        "\n",
        "config = videointelligence.SpeechTranscriptionConfig(\n",
        "    language_code=\"en-US\", enable_automatic_punctuation=True\n",
        ")\n",
        "video_context = videointelligence.VideoContext(speech_transcription_config=config)"
      ],
      "metadata": {
        "id": "DnrYf_pljqSB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "operation = video_client.annotate_video(\n",
        "    request={\n",
        "        \"features\": features,\n",
        "        \"input_uri\": \"gs://cloud-samples-data/video/JaneGoodall.mp4\",\n",
        "        \"video_context\": video_context,\n",
        "    }\n",
        ")\n",
        "print(\"\\nProcessing video for speech transcription.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP-yorslkAfD",
        "outputId": "415927d3-2467-4165-ce04-4734dcabb350"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing video for speech transcription.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = operation.result(timeout=600)\n",
        "\n",
        "# There is only one annotation_result since only\n",
        "# one video is processed.\n",
        "annotation_results = result.annotation_results[0]\n",
        "for speech_transcription in annotation_results.speech_transcriptions:\n",
        "\n",
        "    # The number of alternatives for each transcription is limited by\n",
        "    # SpeechTranscriptionConfig.max_alternatives.\n",
        "    # Each alternative is a different possible transcription\n",
        "    # and has its own confidence score.\n",
        "    for alternative in speech_transcription.alternatives:\n",
        "        print(\"Alternative level information:\")\n",
        "\n",
        "        print(\"Transcript: {}\".format(alternative.transcript))\n",
        "        print(\"Confidence: {}\\n\".format(alternative.confidence))\n",
        "\n",
        "\n",
        "        print(\"Word level information:\")\n",
        "        for word_info in alternative.words:\n",
        "            word = word_info.word\n",
        "            start_time = word_info.start_time\n",
        "            end_time = word_info.end_time\n",
        "            print(\n",
        "                \"\\t{}s - {}s: {}\".format(\n",
        "                    start_time.seconds + start_time.microseconds * 1e-6,\n",
        "                    end_time.seconds + end_time.microseconds * 1e-6,\n",
        "                    word,\n",
        "                )\n",
        "            )"
      ],
      "metadata": {
        "id": "7FmBp45XkDEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04196cfb-b6d8-486f-ccb1-bb8b0da42fc6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alternative level information:\n",
            "Transcript: \n",
            "Confidence: 0.0\n",
            "\n",
            "Word level information:\n",
            "Alternative level information:\n",
            "Transcript: \n",
            "Confidence: 0.0\n",
            "\n",
            "Word level information:\n",
            "Alternative level information:\n",
            "Transcript: \n",
            "Confidence: 0.0\n",
            "\n",
            "Word level information:\n",
            "Alternative level information:\n",
            "Transcript: \n",
            "Confidence: 0.0\n",
            "\n",
            "Word level information:\n",
            "Alternative level information:\n",
            "Transcript: I remember, I was struck by the harmony of color and the forest shades of yellow and green, beeping to the Browns and purples. And the way the vines curled up through the trees, clinging to twigs and branches,\n",
            "Confidence: 0.8694230914115906\n",
            "\n",
            "Word level information:\n",
            "\t28.8s - 28.9s: I\n",
            "\t28.9s - 29.4s: remember,\n",
            "\t29.4s - 29.5s: I\n",
            "\t29.5s - 29.7s: was\n",
            "\t29.7s - 30.2s: struck\n",
            "\t30.2s - 30.3s: by\n",
            "\t30.3s - 30.4s: the\n",
            "\t30.4s - 30.9s: harmony\n",
            "\t30.9s - 31.1s: of\n",
            "\t31.1s - 31.5s: color\n",
            "\t31.5s - 31.6s: and\n",
            "\t31.6s - 31.7s: the\n",
            "\t31.7s - 32.5s: forest\n",
            "\t33.1s - 33.6s: shades\n",
            "\t33.6s - 33.7s: of\n",
            "\t33.7s - 34.1s: yellow\n",
            "\t34.1s - 34.3s: and\n",
            "\t34.3s - 34.9s: green,\n",
            "\t35.1s - 35.7s: beeping\n",
            "\t35.7s - 35.8s: to\n",
            "\t35.8s - 35.9s: the\n",
            "\t35.9s - 36.5s: Browns\n",
            "\t36.5s - 36.7s: and\n",
            "\t36.7s - 37.5s: purples.\n",
            "\t38.4s - 38.5s: And\n",
            "\t38.5s - 38.6s: the\n",
            "\t38.6s - 38.7s: way\n",
            "\t38.7s - 38.9s: the\n",
            "\t38.9s - 39.4s: vines\n",
            "\t39.4s - 39.9s: curled\n",
            "\t39.9s - 40.0s: up\n",
            "\t40.0s - 40.2s: through\n",
            "\t40.2s - 40.4s: the\n",
            "\t40.4s - 41.0s: trees,\n",
            "\t41.1s - 41.6s: clinging\n",
            "\t41.6s - 41.7s: to\n",
            "\t41.7s - 42.1s: twigs\n",
            "\t42.1s - 42.2s: and\n",
            "\t42.2s - 43.0s: branches,\n",
            "Alternative level information:\n",
            "Transcript:  The gentle breeze rustle, the leaves. So that the shining stars of light gleamed and winked, I was keenly aware of secret movements in the trees.\n",
            "Confidence: 0.9128385186195374\n",
            "\n",
            "Word level information:\n",
            "\t44.1s - 44.2s: The\n",
            "\t44.2s - 44.6s: gentle\n",
            "\t44.6s - 45.1s: breeze\n",
            "\t45.1s - 45.4s: rustle,\n",
            "\t45.4s - 45.5s: the\n",
            "\t45.5s - 46.2s: leaves.\n",
            "\t46.3s - 46.5s: So\n",
            "\t46.5s - 46.7s: that\n",
            "\t46.7s - 46.8s: the\n",
            "\t46.8s - 47.3s: shining\n",
            "\t47.3s - 47.8s: stars\n",
            "\t47.8s - 47.9s: of\n",
            "\t47.9s - 48.3s: light\n",
            "\t48.3s - 48.8s: gleamed\n",
            "\t48.8s - 49.0s: and\n",
            "\t49.0s - 49.8s: winked,\n",
            "\t55.4s - 55.4s: I\n",
            "\t55.4s - 55.7s: was\n",
            "\t55.7s - 56.1s: keenly\n",
            "\t56.1s - 56.6s: aware\n",
            "\t56.6s - 56.7s: of\n",
            "\t56.7s - 57.2s: secret\n",
            "\t57.2s - 57.8s: movements\n",
            "\t57.8s - 57.9s: in\n",
            "\t57.9s - 58.0s: the\n",
            "\t58.0s - 58.8s: trees.\n",
            "Alternative level information:\n",
            "Transcript: \n",
            "Confidence: 0.0\n",
            "\n",
            "Word level information:\n",
            "Alternative level information:\n",
            "Transcript:  I looked into his large and lustrous eyes. They seemed somehow to express his entire personality, his Serene self-assurance, what? An amazing privilege. It was to be utterly accepted by us by a wild free animal.\n",
            "Confidence: 0.9128383994102478\n",
            "\n",
            "Word level information:\n",
            "\t72.4s - 72.5s: I\n",
            "\t72.5s - 72.8s: looked\n",
            "\t72.8s - 73.0s: into\n",
            "\t73.0s - 73.2s: his\n",
            "\t73.2s - 73.7s: large\n",
            "\t73.7s - 73.8s: and\n",
            "\t73.8s - 74.4s: lustrous\n",
            "\t74.4s - 75.0s: eyes.\n",
            "\t75.5s - 75.7s: They\n",
            "\t75.7s - 76.1s: seemed\n",
            "\t76.1s - 76.5s: somehow\n",
            "\t76.5s - 76.7s: to\n",
            "\t76.7s - 77.2s: express\n",
            "\t77.2s - 77.3s: his\n",
            "\t77.3s - 78.0s: entire\n",
            "\t78.0s - 79.1s: personality,\n",
            "\t79.5s - 79.7s: his\n",
            "\t79.7s - 80.2s: Serene\n",
            "\t80.2s - 81.5s: self-assurance,\n",
            "\t82.6s - 82.8s: what?\n",
            "\t82.8s - 82.9s: An\n",
            "\t82.9s - 83.5s: amazing\n",
            "\t83.5s - 84.1s: privilege.\n",
            "\t84.1s - 84.2s: It\n",
            "\t84.2s - 84.8s: was\n",
            "\t85.2s - 85.3s: to\n",
            "\t85.3s - 85.6s: be\n",
            "\t85.6s - 85.9s: utterly\n",
            "\t85.9s - 86.6s: accepted\n",
            "\t86.6s - 86.7s: by\n",
            "\t86.7s - 87.1s: us\n",
            "\t87.3s - 87.5s: by\n",
            "\t87.5s - 87.6s: a\n",
            "\t87.6s - 88.2s: wild\n",
            "\t88.2s - 88.6s: free\n",
            "\t88.6s - 89.2s: animal.\n",
            "Alternative level information:\n",
            "Transcript:  I lay there part of the forest and experienced again that magical enhancement of sound that added richness of perception. I was awed by the beauty\n",
            "Confidence: 0.8648173809051514\n",
            "\n",
            "Word level information:\n",
            "\t96.2s - 96.3s: I\n",
            "\t96.3s - 96.6s: lay\n",
            "\t96.6s - 97.0s: there\n",
            "\t97.0s - 97.3s: part\n",
            "\t97.3s - 97.4s: of\n",
            "\t97.4s - 97.5s: the\n",
            "\t97.5s - 98.4s: forest\n",
            "\t98.4s - 98.5s: and\n",
            "\t98.5s - 99.4s: experienced\n",
            "\t99.4s - 99.7s: again\n",
            "\t99.7s - 100.0s: that\n",
            "\t100.0s - 100.6s: magical\n",
            "\t100.6s - 101.4s: enhancement\n",
            "\t101.4s - 101.5s: of\n",
            "\t101.5s - 102.3s: sound\n",
            "\t102.5s - 102.8s: that\n",
            "\t102.8s - 103.1s: added\n",
            "\t103.1s - 103.7s: richness\n",
            "\t103.7s - 103.8s: of\n",
            "\t103.8s - 104.7s: perception.\n",
            "\t109.8s - 109.9s: I\n",
            "\t109.9s - 110.2s: was\n",
            "\t110.2s - 110.6s: awed\n",
            "\t110.6s - 110.8s: by\n",
            "\t110.8s - 110.9s: the\n",
            "\t110.9s - 111.5s: beauty\n",
            "Alternative level information:\n",
            "Transcript:  and I found myself thinking, this is where I belong together, the chimpanzees and the baboons, and the monkeys, the birds, and insects the teeming life of the vibrant Forest, the stirrings of the nether, Still Waters of the Great Lake formed one hole,\n",
            "Confidence: 0.9114207625389099\n",
            "\n",
            "Word level information:\n",
            "\t112.9s - 113.1s: and\n",
            "\t113.1s - 113.2s: I\n",
            "\t113.2s - 113.5s: found\n",
            "\t113.5s - 113.9s: myself\n",
            "\t113.9s - 114.5s: thinking,\n",
            "\t114.9s - 115.2s: this\n",
            "\t115.2s - 115.4s: is\n",
            "\t115.4s - 115.6s: where\n",
            "\t115.6s - 115.7s: I\n",
            "\t115.7s - 116.3s: belong\n",
            "\t122.0s - 122.7s: together,\n",
            "\t122.7s - 122.8s: the\n",
            "\t122.8s - 123.7s: chimpanzees\n",
            "\t123.7s - 123.9s: and\n",
            "\t123.9s - 124.0s: the\n",
            "\t124.0s - 124.6s: baboons,\n",
            "\t124.6s - 124.7s: and\n",
            "\t124.7s - 124.8s: the\n",
            "\t124.8s - 125.5s: monkeys,\n",
            "\t125.9s - 126.0s: the\n",
            "\t126.0s - 126.5s: birds,\n",
            "\t126.5s - 126.6s: and\n",
            "\t126.6s - 127.5s: insects\n",
            "\t127.9s - 128.0s: the\n",
            "\t128.0s - 128.5s: teeming\n",
            "\t128.5s - 128.8s: life\n",
            "\t128.8s - 128.9s: of\n",
            "\t128.9s - 129.0s: the\n",
            "\t129.0s - 129.6s: vibrant\n",
            "\t129.6s - 130.5s: Forest,\n",
            "\t131.1s - 131.2s: the\n",
            "\t131.2s - 131.8s: stirrings\n",
            "\t131.8s - 131.9s: of\n",
            "\t131.9s - 132.0s: the\n",
            "\t132.0s - 132.3s: nether,\n",
            "\t132.3s - 132.7s: Still\n",
            "\t132.7s - 133.1s: Waters\n",
            "\t133.1s - 133.2s: of\n",
            "\t133.2s - 133.3s: the\n",
            "\t133.3s - 133.6s: Great\n",
            "\t133.6s - 134.2s: Lake\n",
            "\t135.3s - 135.8s: formed\n",
            "\t135.8s - 136.1s: one\n",
            "\t136.1s - 136.7s: hole,\n",
            "Alternative level information:\n",
            "Transcript:  All one.\n",
            "Confidence: 0.8633294105529785\n",
            "\n",
            "Word level information:\n",
            "\t139.7s - 140.0s: All\n",
            "\t140.0s - 140.4s: one.\n",
            "Alternative level information:\n",
            "Transcript: \n",
            "Confidence: 0.0\n",
            "\n",
            "Word level information:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_irOs9RDkQra",
        "outputId": "b2f5e1f6-391c-43f0-b952-5800de9b5e66"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "annotation_results {\n",
            "  input_uri: \"/cloud-samples-data/video/JaneGoodall.mp4\"\n",
            "  segment {\n",
            "    start_time_offset {\n",
            "    }\n",
            "    end_time_offset {\n",
            "      seconds: 162\n",
            "      nanos: 539682000\n",
            "    }\n",
            "  }\n",
            "  speech_transcriptions {\n",
            "    alternatives {\n",
            "    }\n",
            "    language_code: \"en-us\"\n",
            "  }\n",
            "  speech_transcriptions {\n",
            "    alternatives {\n",
            "    }\n",
            "    language_code: \"en-us\"\n",
            "  }\n",
            "  speech_transcriptions {\n",
            "    alternatives {\n",
            "    }\n",
            "    language_code: \"en-us\"\n",
            "  }\n",
            "  speech_transcriptions {\n",
            "    alternatives {\n",
            "    }\n",
            "    language_code: \"en-us\"\n",
            "  }\n",
            "  speech_transcriptions {\n",
            "    alternatives {\n",
            "      transcript: \"I remember, I was struck by the harmony of color and the forest shades of yellow and green, beeping to the Browns and purples. And the way the vines curled up through the trees, clinging to twigs and branches,\"\n",
            "      confidence: 0.869423091\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 28\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 28\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"I\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 28\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 29\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        word: \"remember,\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 29\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 29\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"I\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 29\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 29\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"was\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 29\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 30\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"struck\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 30\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 30\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        word: \"by\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 30\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 30\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 30\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 30\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"harmony\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 30\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 31\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        word: \"of\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 31\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 31\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"color\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 31\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 31\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"and\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 31\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 31\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 31\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 32\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"forest\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 33\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 33\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"shades\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 33\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 33\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"of\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 33\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 34\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        word: \"yellow\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 34\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 34\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        word: \"and\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 34\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 34\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"green,\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 35\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 35\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"beeping\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 35\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 35\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"to\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 35\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 35\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 35\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 36\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"Browns\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 36\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 36\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"and\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 36\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 37\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"purples.\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 38\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 38\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"And\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 38\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 38\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 38\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 38\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"way\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 38\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 38\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 38\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 39\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        word: \"vines\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 39\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 39\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"curled\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 39\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 40\n",
            "        }\n",
            "        word: \"up\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 40\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 40\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"through\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 40\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 40\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 40\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 41\n",
            "        }\n",
            "        word: \"trees,\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 41\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 41\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"clinging\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 41\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 41\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"to\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 41\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 42\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        word: \"twigs\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 42\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 42\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"and\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 42\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 43\n",
            "        }\n",
            "        word: \"branches,\"\n",
            "      }\n",
            "    }\n",
            "    language_code: \"en-us\"\n",
            "  }\n",
            "  speech_transcriptions {\n",
            "    alternatives {\n",
            "      transcript: \" The gentle breeze rustle, the leaves. So that the shining stars of light gleamed and winked, I was keenly aware of secret movements in the trees.\"\n",
            "      confidence: 0.912838519\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 44\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 44\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"The\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 44\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 44\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"gentle\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 44\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 45\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        word: \"breeze\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 45\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 45\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        word: \"rustle,\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 45\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 45\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 45\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 46\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"leaves.\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 46\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 46\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"So\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 46\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 46\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"that\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 46\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 46\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 46\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 47\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        word: \"shining\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 47\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 47\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"stars\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 47\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 47\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"of\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 47\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 48\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        word: \"light\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 48\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 48\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"gleamed\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 48\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 49\n",
            "        }\n",
            "        word: \"and\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 49\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 49\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"winked,\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 55\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 55\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        word: \"I\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 55\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 55\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"was\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 55\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 56\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        word: \"keenly\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 56\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 56\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"aware\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 56\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 56\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"of\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 56\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 57\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"secret\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 57\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 57\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"movements\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 57\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 57\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"in\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 57\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 58\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 58\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 58\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"trees.\"\n",
            "      }\n",
            "    }\n",
            "    language_code: \"en-us\"\n",
            "  }\n",
            "  speech_transcriptions {\n",
            "    alternatives {\n",
            "    }\n",
            "    language_code: \"en-us\"\n",
            "  }\n",
            "  speech_transcriptions {\n",
            "    alternatives {\n",
            "      transcript: \" I looked into his large and lustrous eyes. They seemed somehow to express his entire personality, his Serene self-assurance, what? An amazing privilege. It was to be utterly accepted by us by a wild free animal.\"\n",
            "      confidence: 0.912838399\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 72\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 72\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"I\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 72\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 72\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"looked\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 72\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 73\n",
            "        }\n",
            "        word: \"into\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 73\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 73\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"his\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 73\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 73\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"large\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 73\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 73\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"and\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 73\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 74\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        word: \"lustrous\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 74\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 75\n",
            "        }\n",
            "        word: \"eyes.\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 75\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 75\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"They\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 75\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 76\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        word: \"seemed\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 76\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 76\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"somehow\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 76\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 76\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"to\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 76\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 77\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"express\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 77\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 77\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        word: \"his\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 77\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 78\n",
            "        }\n",
            "        word: \"entire\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 78\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 79\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        word: \"personality,\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 79\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 79\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"his\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 79\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 80\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"Serene\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 80\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 81\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"self-assurance,\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 82\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 82\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"what?\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 82\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 82\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"An\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 82\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 83\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"amazing\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 83\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 84\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        word: \"privilege.\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 84\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 84\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"It\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 84\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 84\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"was\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 85\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 85\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        word: \"to\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 85\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 85\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"be\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 85\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 85\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"utterly\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 85\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 86\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"accepted\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 86\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 86\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"by\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 86\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 87\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        word: \"us\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 87\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 87\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"by\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 87\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 87\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"a\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 87\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 88\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"wild\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 88\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 88\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"free\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 88\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 89\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"animal.\"\n",
            "      }\n",
            "    }\n",
            "    language_code: \"en-us\"\n",
            "  }\n",
            "  speech_transcriptions {\n",
            "    alternatives {\n",
            "      transcript: \" I lay there part of the forest and experienced again that magical enhancement of sound that added richness of perception. I was awed by the beauty\"\n",
            "      confidence: 0.864817381\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 96\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 96\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        word: \"I\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 96\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 96\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"lay\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 96\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 97\n",
            "        }\n",
            "        word: \"there\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 97\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 97\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        word: \"part\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 97\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 97\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        word: \"of\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 97\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 97\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 97\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 98\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        word: \"forest\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 98\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 98\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"and\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 98\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 99\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        word: \"experienced\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 99\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 99\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"again\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 99\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 100\n",
            "        }\n",
            "        word: \"that\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 100\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 100\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"magical\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 100\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 101\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        word: \"enhancement\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 101\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 101\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"of\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 101\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 102\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        word: \"sound\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 102\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 102\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"that\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 102\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 103\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        word: \"added\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 103\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 103\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"richness\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 103\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 103\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"of\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 103\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 104\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"perception.\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 109\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 109\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"I\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 109\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 110\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"was\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 110\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 110\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"awed\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 110\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 110\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"by\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 110\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 110\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 110\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 111\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"beauty\"\n",
            "      }\n",
            "    }\n",
            "    language_code: \"en-us\"\n",
            "  }\n",
            "  speech_transcriptions {\n",
            "    alternatives {\n",
            "      transcript: \" and I found myself thinking, this is where I belong together, the chimpanzees and the baboons, and the monkeys, the birds, and insects the teeming life of the vibrant Forest, the stirrings of the nether, Still Waters of the Great Lake formed one hole,\"\n",
            "      confidence: 0.911420763\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 112\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 113\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        word: \"and\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 113\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 113\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"I\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 113\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 113\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"found\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 113\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 113\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"myself\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 113\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 114\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"thinking,\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 114\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 115\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"this\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 115\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 115\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        word: \"is\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 115\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 115\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"where\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 115\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 115\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"I\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 115\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 116\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        word: \"belong\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 122\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 122\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"together,\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 122\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 122\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 122\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 123\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"chimpanzees\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 123\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 123\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"and\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 123\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 124\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 124\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 124\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"baboons,\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 124\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 124\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"and\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 124\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 124\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 124\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 125\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"monkeys,\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 125\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 126\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 126\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 126\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"birds,\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 126\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 126\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"and\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 126\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 127\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"insects\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 127\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 128\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 128\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 128\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"teeming\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 128\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 128\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"life\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 128\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 128\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"of\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 128\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 129\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 129\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 129\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"vibrant\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 129\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 130\n",
            "          nanos: 500000000\n",
            "        }\n",
            "        word: \"Forest,\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 131\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 131\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 131\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 131\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"stirrings\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 131\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 131\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        word: \"of\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 131\n",
            "          nanos: 900000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 132\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 132\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 132\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        word: \"nether,\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 132\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 132\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"Still\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 132\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 133\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        word: \"Waters\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 133\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 133\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"of\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 133\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 133\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        word: \"the\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 133\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 133\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        word: \"Great\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 133\n",
            "          nanos: 600000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 134\n",
            "          nanos: 200000000\n",
            "        }\n",
            "        word: \"Lake\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 135\n",
            "          nanos: 300000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 135\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        word: \"formed\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 135\n",
            "          nanos: 800000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 136\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        word: \"one\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 136\n",
            "          nanos: 100000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 136\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        word: \"hole,\"\n",
            "      }\n",
            "    }\n",
            "    language_code: \"en-us\"\n",
            "  }\n",
            "  speech_transcriptions {\n",
            "    alternatives {\n",
            "      transcript: \" All one.\"\n",
            "      confidence: 0.863329411\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 139\n",
            "          nanos: 700000000\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 140\n",
            "        }\n",
            "        word: \"All\"\n",
            "      }\n",
            "      words {\n",
            "        start_time {\n",
            "          seconds: 140\n",
            "        }\n",
            "        end_time {\n",
            "          seconds: 140\n",
            "          nanos: 400000000\n",
            "        }\n",
            "        word: \"one.\"\n",
            "      }\n",
            "    }\n",
            "    language_code: \"en-us\"\n",
            "  }\n",
            "  speech_transcriptions {\n",
            "    alternatives {\n",
            "    }\n",
            "    language_code: \"en-us\"\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_client = vi.VideoIntelligenceServiceClient()\n",
        "features = [vi.Feature.SPEECH_TRANSCRIPTION]\n",
        "\n",
        "segments = vi.VideoSegment(\n",
        "    start_time_offset=timedelta(seconds=0),\n",
        "    end_time_offset=timedelta(seconds=37),\n",
        ")\n",
        "config = vi.SpeechTranscriptionConfig(\n",
        "    language_code=\"en-US\", enable_automatic_punctuation=True\n",
        ")\n",
        "video_context = vi.VideoContext(segments=[segments], speech_transcription_config=config)\n",
        "\n",
        "operation = video_client.annotate_video(\n",
        "    request={\n",
        "        \"features\": features,\n",
        "        \"input_uri\": \"gs://cloud-samples-data/video/JaneGoodall.mp4\",\n",
        "        \"video_context\": video_context,\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"\\nProcessing video for speech transcription.\")\n",
        "\n",
        "result = operation.result(timeout=600)\n",
        "\n",
        "# There is only one annotation_result since only\n",
        "# one video is processed.\n",
        "annotation_results = result.annotation_results[0]\n",
        "\n",
        "# Initialize variables to track the alternative with the highest confidence\n",
        "highest_confidence = 0\n",
        "best_transcription = None\n",
        "\n",
        "for speech_transcription in annotation_results.speech_transcriptions:\n",
        "    # The number of alternatives for each transcription is limited by\n",
        "    # SpeechTranscriptionConfig.max_alternatives.\n",
        "    # Each alternative is a different possible transcription\n",
        "    # and has its own confidence score.\n",
        "    for alternative in speech_transcription.alternatives:\n",
        "        print(\"Alternative level information:\")\n",
        "\n",
        "        print(\"Transcript: {}\".format(alternative.transcript))\n",
        "        print(\"Confidence: {}\\n\".format(alternative.confidence))\n",
        "\n",
        "        print(\"Word level information:\")\n",
        "        for word_info in alternative.words:\n",
        "            word = word_info.word\n",
        "            start_time = word_info.start_time\n",
        "            end_time = word_info.end_time\n",
        "            print(\n",
        "                \"\\t{}s - {}s: {}\".format(\n",
        "                    start_time.seconds + start_time.microseconds * 1e-6,\n",
        "                    end_time.seconds + end_time.microseconds * 1e-6,\n",
        "                    word,\n",
        "                )\n",
        "            )\n",
        "        if alternative.confidence > highest_confidence:\n",
        "            highest_confidence = alternative.confidence\n",
        "            best_transcription = alternative.transcript"
      ],
      "metadata": {
        "id": "okVtXCLvlHsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c876bb21-ac09-4106-971f-579ca037673e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing video for speech transcription.\n",
            "Alternative level information:\n",
            "Transcript: \n",
            "Confidence: 0.0\n",
            "\n",
            "Word level information:\n",
            "Alternative level information:\n",
            "Transcript: \n",
            "Confidence: 0.0\n",
            "\n",
            "Word level information:\n",
            "Alternative level information:\n",
            "Transcript: \n",
            "Confidence: 0.0\n",
            "\n",
            "Word level information:\n",
            "Alternative level information:\n",
            "Transcript: \n",
            "Confidence: 0.0\n",
            "\n",
            "Word level information:\n",
            "Alternative level information:\n",
            "Transcript: remember I was struck by the harmony of color in the forest shades of yellow and green deepening to the Browns and per\n",
            "Confidence: 0.7856012582778931\n",
            "\n",
            "Word level information:\n",
            "\t28.9s - 29.4s: remember\n",
            "\t29.4s - 29.5s: I\n",
            "\t29.5s - 29.7s: was\n",
            "\t29.7s - 30.2s: struck\n",
            "\t30.2s - 30.3s: by\n",
            "\t30.3s - 30.5s: the\n",
            "\t30.5s - 30.9s: harmony\n",
            "\t30.9s - 31.1s: of\n",
            "\t31.1s - 31.5s: color\n",
            "\t31.5s - 31.6s: in\n",
            "\t31.6s - 31.7s: the\n",
            "\t31.7s - 32.6s: forest\n",
            "\t33.1s - 33.6s: shades\n",
            "\t33.6s - 33.7s: of\n",
            "\t33.7s - 34.1s: yellow\n",
            "\t34.1s - 34.3s: and\n",
            "\t34.3s - 34.9s: green\n",
            "\t35.1s - 35.7s: deepening\n",
            "\t35.7s - 35.8s: to\n",
            "\t35.8s - 35.9s: the\n",
            "\t35.9s - 36.5s: Browns\n",
            "\t36.5s - 36.7s: and\n",
            "\t36.7s - 36.8s: per\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_transcription"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CXhO-64Tl_O5",
        "outputId": "1c1feb2c-02a2-4d25-ec5c-d99d765146d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'remember I was struck by the harmony of color in the forest shades of yellow and green deepening to the Browns and per'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding label and text transcribe"
      ],
      "metadata": {
        "id": "ZgfuxfEComrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q \"google-generativeai>=0.8.3\""
      ],
      "metadata": {
        "id": "5j1taYNZqUL1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "e3-oDeQ7qYbI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "3MtIf2A-qcYT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def get_embeddings(text: list[str]) -> np.ndarray:\n",
        "  embeddings = genai.embed_content(model='models/text-embedding-004',\n",
        "                               content=text,\n",
        "                               task_type='semantic_similarity')\n",
        "  embds = embeddings.get('embedding', None)\n",
        "  embds = np.array(embds).reshape(len(embds), -1)\n",
        "  return embds"
      ],
      "metadata": {
        "id": "nmXHGzt2rB1X"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_label_embedding = get_embeddings(' '.join(video_labels))\n",
        "transcription_embedding = get_embeddings(best_transcription)"
      ],
      "metadata": {
        "id": "8uOFj3Do4yv3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JO7TTO4A5nqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the embedding database with ChromaDB"
      ],
      "metadata": {
        "id": "-mhaIIAA7Mvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0MxOxs_z7fL5",
        "outputId": "14e81126-0053-4793-c864-26cf9dc92f3b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.5)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.10.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.69.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.1.21)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.29.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.10.0-py2.py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53771 sha256=d74e8857057dadd392ffb43e7ace5f446e471154ef331c2ed6645a03fefb5311\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, importlib-metadata, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.7 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.5.0 kubernetes-32.0.0 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-api-1.29.0 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-proto-1.29.0 opentelemetry-sdk-1.29.0 opentelemetry-semantic-conventions-0.50b0 opentelemetry-util-http-0.50b0 overrides-7.7.0 posthog-3.10.0 protobuf-5.29.3 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 starlette-0.45.3 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "835782f0ccb84569ba0eb0637402c06c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "from google.api_core import retry"
      ],
      "metadata": {
        "id": "kR11LKp47PRw"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "    # Specify whether to generate embeddings for videos, or queries\n",
        "    video_mode = True\n",
        "\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        if self.video_mode_mode:\n",
        "            embedding_task = \"retrieval_document\"\n",
        "        else:\n",
        "            embedding_task = \"retrieval_query\"\n",
        "\n",
        "        retry_policy = {\"retry\": retry.Retry(predicate=retry.if_transient_error)}\n",
        "\n",
        "        response = genai.embed_content(\n",
        "            model=\"models/text-embedding-004\",\n",
        "            content=input,\n",
        "            task_type=embedding_task,\n",
        "            request_options=retry_policy,\n",
        "        )\n",
        "        return response[\"embedding\"]"
      ],
      "metadata": {
        "id": "VOt7ND5Y7yIZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "\n",
        "DB_NAME = \"googlecardb\"\n",
        "embed_fn = GeminiEmbeddingFunction()\n",
        "embed_fn.video_mode_mode = True\n",
        "\n",
        "chroma_client = chromadb.Client()\n",
        "db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
        "video_doc = \" \".join(video_labels) + \" \" + best_transcription\n",
        "documents = [video_doc]\n",
        "\n",
        "db.add(documents=documents, ids=[str(i) for i in range(len(documents))])\n",
        "video_doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "opo6axVjA-iq",
        "outputId": "51c9dd43-47fa-4b31-a7c9-995157a3f670"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'planet earth water resources aerial photography vegetation nature leaf sunlight flora moisture tree forest grove woodland ecosystem old growth forest temperate broadleaf and mixed forest nature reserve jungle stream moss rainforest insect moths and butterflies butterfly monarch butterfly animal invertebrate pollinator remember I was struck by the harmony of color in the forest shades of yellow and green deepening to the Browns and per'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm that the data was inserted by looking at the database.\n",
        "db.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWTzSDM2EDs1",
        "outputId": "87d325cd-2a4f-4e0b-ee91-db96c7be3847"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval: Find relevant documents"
      ],
      "metadata": {
        "id": "OU0ssXu1GG1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Switch to query mode when generating embeddings.\n",
        "embed_fn.video_mode = False\n",
        "\n",
        "# Search the Chroma DB using the specified query- based on the user interests\n",
        "query = \"Nature\"\n",
        "\n",
        "result = db.query(query_texts=[query], n_results=1)\n",
        "[[passage]] = result[\"documents\"]\n",
        "\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "ktdprm7fGRAu",
        "outputId": "dbc0786b-7ef8-43ad-9b85-b1b4801c9c97"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': [['0']],\n",
              " 'embeddings': None,\n",
              " 'documents': [['planet earth water resources aerial photography vegetation nature leaf sunlight flora moisture tree forest grove woodland ecosystem old growth forest temperate broadleaf and mixed forest nature reserve jungle stream moss rainforest insect moths and butterflies butterfly monarch butterfly animal invertebrate pollinator remember I was struck by the harmony of color in the forest shades of yellow and green deepening to the Browns and per']],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'metadatas': [[None]],\n",
              " 'distances': [[0.663965106010437]],\n",
              " 'included': [<IncludeEnum.distances: 'distances'>,\n",
              "  <IncludeEnum.documents: 'documents'>,\n",
              "  <IncludeEnum.metadatas: 'metadatas'>]}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use id to retrieve the actual video"
      ],
      "metadata": {
        "id": "SPxYUaQQGgwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lmMCtKjTGqYv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}